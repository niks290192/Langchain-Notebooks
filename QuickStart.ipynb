{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\r\n",
      "  Downloading langchain-0.0.141-py3-none-any.whl (540 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m540.8/540.8 kB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting pydantic<2,>=1\r\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-macosx_10_9_x86_64.whl (2.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting requests<3,>=2\r\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\r\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\r\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\r\n",
      "Collecting gptcache>=0.1.7\r\n",
      "  Downloading gptcache-0.1.12-py3-none-any.whl (52 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.6/52.6 kB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting numpy<2,>=1\r\n",
      "  Using cached numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\r\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\r\n",
      "  Using cached aiohttp-3.8.4-cp39-cp39-macosx_10_9_x86_64.whl (360 kB)\r\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\r\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m90.0/90.0 kB\u001B[0m \u001B[31m12.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting SQLAlchemy<2,>=1\r\n",
      "  Using cached SQLAlchemy-1.4.47-cp39-cp39-macosx_11_0_x86_64.whl (1.6 MB)\r\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\r\n",
      "  Using cached dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\r\n",
      "Collecting tenacity<9.0.0,>=8.1.0\r\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from langchain) (6.0)\r\n",
      "Collecting multidict<7.0,>=4.5\r\n",
      "  Using cached multidict-6.0.4-cp39-cp39-macosx_10_9_x86_64.whl (29 kB)\r\n",
      "Collecting frozenlist>=1.1.1\r\n",
      "  Using cached frozenlist-1.3.3-cp39-cp39-macosx_10_9_x86_64.whl (36 kB)\r\n",
      "Collecting aiosignal>=1.1.2\r\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Collecting charset-normalizer<4.0,>=2.0\r\n",
      "  Using cached charset_normalizer-3.1.0-cp39-cp39-macosx_10_9_x86_64.whl (124 kB)\r\n",
      "Collecting yarl<2.0,>=1.0\r\n",
      "  Using cached yarl-1.8.2-cp39-cp39-macosx_10_9_x86_64.whl (61 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\r\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\r\n",
      "  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\r\n",
      "Collecting typing-inspect>=0.4.0\r\n",
      "  Using cached typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\r\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\r\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\r\n",
      "Collecting cachetools\r\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\r\n",
      "Collecting openai\r\n",
      "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m70.3/70.3 kB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\r\n",
      "Collecting certifi>=2017.4.17\r\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\r\n",
      "Collecting urllib3<1.27,>=1.21.1\r\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m140.9/140.9 kB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: idna<4,>=2.5 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4)\r\n",
      "Collecting greenlet!=0.4.17\r\n",
      "  Using cached greenlet-2.0.2-cp39-cp39-macosx_11_0_x86_64.whl (241 kB)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\r\n",
      "Collecting mypy-extensions>=0.3.0\r\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\r\n",
      "Collecting tqdm\r\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\r\n",
      "Installing collected packages: urllib3, tqdm, tenacity, pydantic, numpy, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, charset-normalizer, certifi, cachetools, async-timeout, yarl, typing-inspect, SQLAlchemy, requests, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, openai, gptcache, langchain\r\n",
      "Successfully installed SQLAlchemy-1.4.47 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 dataclasses-json-0.5.7 frozenlist-1.3.3 gptcache-0.1.12 greenlet-2.0.2 langchain-0.0.141 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 numpy-1.24.2 openai-0.27.4 openapi-schema-pydantic-1.2.4 pydantic-1.10.7 requests-2.28.2 tenacity-8.2.2 tqdm-4.65.0 typing-inspect-0.8.0 urllib3-1.26.15 yarl-1.8.2\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:58:57.927969Z",
     "end_time": "2023-04-17T17:59:10.098947Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (0.27.4)\r\n",
      "Requirement already satisfied: requests>=2.20 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from openai) (2.28.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from openai) (4.65.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from openai) (3.8.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from requests>=2.20->openai) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from requests>=2.20->openai) (3.1.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from aiohttp->openai) (1.3.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from aiohttp->openai) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from aiohttp->openai) (1.8.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:59:15.939214Z",
     "end_time": "2023-04-17T17:59:17.225969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:00:16.886968Z",
     "end_time": "2023-04-17T18:00:16.899935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:00:22.780781Z",
     "end_time": "2023-04-17T18:00:31.465992Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:00:35.262935Z",
     "end_time": "2023-04-17T18:00:35.284881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Rome, Italy \n",
      "2. Bologna, Italy \n",
      "3. Sicily, Italy \n",
      "4. Venice, Italy \n",
      "5. Naples, Italy\n"
     ]
    }
   ],
   "source": [
    "text = \"What are 5 vacation destinations for someone who likes to eat pasta?\"\n",
    "print(llm(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:00:42.057816Z",
     "end_time": "2023-04-17T18:00:43.945211Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:00:57.930763Z",
     "end_time": "2023-04-17T18:00:57.944105Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:01:23.646948Z",
     "end_time": "2023-04-17T18:01:23.649083Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 5 vacation destinations for someone who likes to eat dessert?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food=\"dessert\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:01:26.583514Z",
     "end_time": "2023-04-17T18:01:26.591683Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Paris, France – known for its world-renowned patisseries and chocolatiers.\n",
      "2. Rome, Italy – delicious gelato, tiramisu, and cannoli.\n",
      "3. Hong Kong – dim sum and egg tarts.\n",
      "4. Bangkok, Thailand – mango sticky rice and coconut pancakes.\n",
      "5. Montreal, Canada – crepes and poutine.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=\"dessert\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:02:27.589528Z",
     "end_time": "2023-04-17T18:02:30.473293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:03:11.495384Z",
     "end_time": "2023-04-17T18:03:11.508687Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:03:28.518190Z",
     "end_time": "2023-04-17T18:03:28.528002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:03:32.887818Z",
     "end_time": "2023-04-17T18:03:32.895135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Canary Islands, Spain - The Canaries are known for their abundance of tropical fruit grown locally and available in specialty markets. \n",
      "\n",
      "2. Hawaii, USA - Hawaii is one of the top vacation destinations for fruit lovers, as it is home to a wide variety of exotic fruits, including papaya, guava, pineapple, and mango.\n",
      "\n",
      "3. Dominican Republic - The Dominican Republic is well known for its abundance of tropical fruits, especially mangoes, coconuts, and bananas.\n",
      "\n",
      "4. Costa Rica - Costa Rica is a top destination for those looking to taste a wide range of fruit, including papaya, passionfruit, and pineapple.\n",
      "\n",
      "5. Bali, Indonesia - Bali is a haven for fruit lovers, with a vast array of exotic fruits grown in the region, such as coconuts, mangosteen, mangos, and bananas.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"fruit\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:03:47.592657Z",
     "end_time": "2023-04-17T18:03:51.736661Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\r\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: requests in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from google-search-results) (2.28.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from requests->google-search-results) (2022.12.7)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from requests->google-search-results) (3.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from requests->google-search-results) (1.26.15)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikhiarora/PycharmProjects/PythonNoteBooks/venv/lib/python3.9/site-packages (from requests->google-search-results) (3.4)\r\n",
      "Building wheels for collected packages: google-search-results\r\n",
      "  Building wheel for google-search-results (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=01aaa5b7d8c1f11ea5708fd86cdb713f463e95b3f65ad5c2ac5b0907b30b2532\r\n",
      "  Stored in directory: /Users/nikhiarora/Library/Caches/pip/wheels/68/8e/73/744b7d9d7ac618849d93081a20e1c0deccd2aef90901c9f5a9\r\n",
      "Successfully built google-search-results\r\n",
      "Installing collected packages: google-search-results\r\n",
      "Successfully installed google-search-results-2.4.2\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:04:26.146553Z",
     "end_time": "2023-04-17T18:04:29.491604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:04:45.828540Z",
     "end_time": "2023-04-17T18:04:45.836869Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:04:55.578899Z",
     "end_time": "2023-04-17T18:04:55.585344Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Load in some tools to use\n",
    "\n",
    "#os.environ[\"SERPAPI_API_KEY\"] = \"\"\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:12:29.261102Z",
     "end_time": "2023-04-17T18:12:29.278065Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent='zero-shot-react-description', verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:12:52.032597Z",
     "end_time": "2023-04-17T18:12:52.034636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m I need to find out who the leader of Japan is and then calculate the largest prime number that is smaller than their age.\n",
      "Action: Search\n",
      "Action Input: \"current leader of Japan\"\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mFumio Kishida\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I need to find out the age of the leader of Japan\n",
      "Action: Search\n",
      "Action Input: \"age of Fumio Kishida\"\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m65 years\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I need to calculate the largest prime number that is smaller than 65\n",
      "Action: Calculator\n",
      "Action Input: 65\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mAnswer: 65\n",
      "\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the final answer\n",
      "Final Answer: The current leader of Japan is Fumio Kishida and the largest prime number that is smaller than their age is 61.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'The current leader of Japan is Fumio Kishida and the largest prime number that is smaller than their age is 61.'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Who is the current leader of Japan? What is the largest prime number that is smaller than their age?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:13:00.921966Z",
     "end_time": "2023-04-17T18:13:14.670191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:13:41.093597Z",
     "end_time": "2023-04-17T18:13:41.108435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:13:48.872474Z",
     "end_time": "2023-04-17T18:13:48.881651Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" Hi there! It's nice to meet you. How can I help you today?\""
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:13:55.907363Z",
     "end_time": "2023-04-17T18:13:56.677082Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:14:06.862266Z",
     "end_time": "2023-04-17T18:14:08.633615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: What was the first thing I said to you?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' You said \"Hi there!\"'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What was the first thing I said to you?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:14:21.083329Z",
     "end_time": "2023-04-17T18:14:21.678890Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: What was the first thing I said to you?\n",
      "AI:  You said \"Hi there!\"\n",
      "Human: what is an alternative phrase for the first thing I said to you?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' An alternative phrase for the first thing you said to me could be \"Greetings!\"'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is an alternative phrase for the first thing I said to you?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T18:14:31.351432Z",
     "end_time": "2023-04-17T18:14:32.791290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
